\documentclass[pscyr,specification,annotation]{itmo-student-thesis}

%% Опции пакета:
%% - specification - если есть, генерируется задание, иначе не генерируется
%% - annotation - если есть, генерируется аннотация, иначе не генерируется
%% - times - делает все шрифтом Times New Roman, собирается с помощью xelatex
%% - pscyr - делает все шрифтом Times New Roman, требует пакета pscyr.

\usepackage{graphicx}
\graphicspath{{logo/}{pics/}}

%% Делает запятую в формулах более интеллектуальной, например:
%% $1,5x$ будет читаться как полтора икса, а не один запятая пять иксов.
%% Однако если написать $1, 5x$, то все будет как прежде.
\usepackage{icomma}

%% Один из пакетов, позволяющий делать таблицы на всю ширину текста.
\usepackage{tabularx}

%% Данные пакеты необязательны к использованию в бакалаврских/магистерских
%% Они нужны для иллюстративных целей
%% Начало
\usepackage{tikz}
\usetikzlibrary{arrows}
\usepackage{filecontents}
\addbibresource{thesis.bib}

\input{./include/labels.tex}

\begin{document}

\studygroup{M3439}
\title{Оптимизация функции, задаваемой регрессионным лесом}
\author{Ягламунов Владислав Радикович}{Ягламунов В.Р.}
\supervisor{Фильченков Андрей Александрович}{Фильченков А.А.}{доцент, к.ф.-м.н.}{}
\publishyear{2019}
%% Дата выдачи задания. Можно не указывать, тогда надо будет заполнить от руки.
% \startdate{01}{сентября}{2018}
%% Срок сдачи студентом работы. Можно не указывать, тогда надо будет заполнить от руки.
% \finishdate{31}{мая}{2019}
%% Дата защиты. Можно не указывать, тогда надо будет заполнить от руки.
% \defencedate{15}{июня}{2019}

% \addconsultant{Белашенков Н.Р.}{канд. физ.-мат. наук, без звания}
% \addconsultant{Беззубик В.В.}{без степени, без звания}

\secretary{Павлова О.Н.}

%% Задание
%%% Техническое задание и исходные данные к работе
\technicalspec{Требуется разработать алгоритм поиска областей минимума
и максимума в данном обученном случайном регрессионном лесе. Требуется
минимизировать время работы алгоритма. Алгоритм должен возвращать точный ответ
или ответ отличающийся от точного не более чем не заданную величину. }

%%% Содержание выпускной квалификационной работы (перечень подлежащих разработке вопросов)
\plannedcontents{Описание существующих решений для оптимизации функции,
задаваемой регрессионным лесом. Разработка и реализация различных алгоритмов,
решающих поставленную задачу. Сравнение разработанных алгоритмов между собой
и существующими решениями задачи. }

%%% Исходные материалы и пособия 
\plannedsources{}

%%% Цель исследования
\researchaim{Разработка эффективного алгоритма оптимизации функции, заданной регрессионным лесом.}

%%% Задачи, решаемые в ВКР
\researchtargets{\begin{enumerate}
    \item реализация интерфейса для работы с обученным случным регрессионным лесом;
    \item разработка алгоритмов оптимизации функции; 
    \item разработка тестирующей системы для алгоритмов оптимизации, позволяющей автоматическое
    тестирование на различных выборках и с набором заданных параметров; 
    \item сравнение и анализ работы разработанных алгоритмов, сопоставление
    с существующими решениями. 
    \end{enumerate}}

%%% Использование современных пакетов компьютерных программ и технологий
\addadvancedsoftware{Пакет \texttt{scikit-learn} с реализацией современных
алгоритмов машинного обучения на языке \texttt{Python}}{****}

%%% Краткая характеристика полученных результатов 
\researchsummary{Получен алгоритм для нахождения оптимума функции, заданной
случным лесом, с возможностью настройки необходимой точности}

%%% Гранты, полученные при выполнении работы 
\researchfunding{При выполнении работы грантов получено не было.}

%%% Наличие публикаций и выступлений на конференциях по теме выпускной работы
\researchpublications{Отсутствуют.}

%% Эта команда генерирует титульный лист и аннотацию.
\maketitle{Бакалавр}

%% Оглавление
\tableofcontents

%% Макрос для введения. Совместим со старым стилевиком.
\startprefacepage

Существует множество алгоритмов, использующих суррогатные функции для
аппроксимации или предсказание различных процессов. Случайный регрессионный лес
часто может применяться в качестве такой функции, так как одно из его
положительных качеств --- возможность эффективно пересчитывать лес при
добавлении новой информации. Так на пример, случайный лес может использоваться
в качестве регрессионной модели для реализации алгоритмов последовательной
оптимизации основанной на модели (Sequential Model-Based Optimization --- SMBO\cite{bro})
Однако, сейчас не существует эффективных оптимизации и применяются неэффективные
алгоритмы, как, например, перебор случайных точек пространства.

%% Начало содержательной части.
\chapter{Описание предметной области и анализ существующих решений}

\section{Случайный регрессионный лес}\label{sec:random_forest}
\subsection{Определение}
Случайный лес (\texttt{Random Forest})\cite{randomforest} --- алгоритм машинного обучения,
основанный на применении ансамбля деревьев принятия решения. Регрессионный лес
используется для решения задач предсказания некоторого численного значения.

\subsection{Обучение}
Для обучения регрессионного леса, исходная выборка разбивается на случайные
подвыборки с повторениями. После чего, на каждой выборке обучается отдельное
дерево принятия решений. Решение принимается как усреднение (возможно
взвешенное) по всем деревьям.


\section{Задача оптимизации}
\subsection{Определение}
Оптимизация --- задача нахождения экстремума (минимума или максимума) целевой
функци в некоторой области. Так как случайный лес разбивает пространство на
конечное число участков, то имеет место случай комбинаторной оптимизации.

\subsection{Методы}

\section{Постановка задачи}

\section{Анализ существующих решений}

\chapter{Алгоритм имитации отжига}

\section{Общий метод}
Алгоритм имитации отжига --- общий метод глобальной оптимизации неявно заданной функции,
основывающийся на имитации работы физического процесса по отжигу металла.
Основная идея --- это постепенно понижающийся температурный параметр,
в зависимости от которого происходит следующая мутация. Чем меньше данный параметр,
тем менее значительной будет следующая мутация. Процесс продолжается до тех пор, пока
температура не упадёт до нуля, то есть больше не будет происходить мутаций.

\section{Оптимизация леса}
Все пространство разбивается на прямоугольную сетку, где каждая прямая соответствует
одной из границ разветвлений в вершине одного из деревьев. 
Для всех прямых также храниться информация в каком дереве происходит разветвление
по данной границе. Важно заметить, что по одному и тому же разбиению могут происходить
несколько вершин в разный деревьях или в одном дереве.

В процессе имитации отжига выполняются случайные мутации по переходу в соседнюю клетку сетки.
Так как при таком переходе пересекается лишь одна граница, для получения нового значения
достаточно пересчитать лишь те деревья в которых есть эта граница, то есть те, что были 
сохранены ранее для границ.

\section{Сравнение}
\subsection{Плюсы метода}
Основное преимущество метода --- это константное время работы, не зависящие от внутренней сложности
устройства конкретных деревьев в лесе.

\subsection{Недостатки метода}
Так как это общий метод оптимизации функции, то данный метод не использует внутреннею 
структуру случайного леса, а рассматривает его как 'чёрный ящик'.
Кроме этого, часто переход в соседнюю клетку происходит по границе, которая не влияет
на текущее значение, следовательно оно не изменяется. В итоге алгоритму приходится
делать большое количество не существенный мутаций, что усложняет его работу.

\subsection{Результаты}
На практике данный метод не показал желаемых результатов, и было принято решение
отказаться от него в пользу более эффективных. Возможно существуют более эффективные
реализации метода имитации отжига, не рассмотренные в данной работе.


\chapter{Эвристический алгоритм}

\section{Перебор}
В алгоритме применяется полный перебор всех поддеревьев. В процессе перебора
поддерживается следующий инвариант: все рассматриваемые поддеревья имеют не
постое пересечение. Тем самым в каждый момент времени рассматривается некоторая
область в виде n-мерного прямоугольника. На каждом шаге перебора, то есть
переходе из вершины в левого или правого ребёнка, эта область разрезается на две
части по трешхолду из вершины, в которой был совершён шаг.

Дополнительно, для каждой вершины посчитано максимальное значение в её
поддереве. Тем самым алгоритм не будет рассматривать поддеревья которые
гарантированно не превосходят ранее найденный ответ.

\section{Эвристика}
Основная эвристическая оптимизация --- перебирать сначала те поддеревья,
в которых разница между левым и правым детьми максимальна. Тем самым как бы
отсекая худший случай.

\[
    i = \arg \max_{v \in trees}(|value[v.left] - value[v.right]|)
\]

\section{Приближенное значение}
Для поиска ответа с заданной точностью применена следующая оптимизация. Алгоритм
не рассматривает те поддеревья которые гарантированно не превосходят ранее
найденный ответ на больше чем заданное $\alpha$.

\[
    value[v] < \alpha current
\]

Это позволяет находить ответ отличающийся от истинного не более чем на заданную
точность, потому что если найденный ответ отличается больше, то не было
рассмотрено его поддерево, что невозможно так как возможный максимум в нем
больше.

\section{Улучшение}

Заметим, что максимум в поддереве может не пересекаться с областью, которую
рассматривает алгоритм в конкретный момент. Из-за этого алгоритм может
перебирать поддеревья, максимум в которых заведомо не достижим.

Чтобы это исправить для каждого дерева принятия решений посчитан отсортированный
список всех его листьев. Данный список строиться путём последовательного слияния
списков детей в каждой вершине, что асимптотически добавляет лишь $O(N \log{N})$
времени к предподсчету алгоритма, где $N$ --- количество листьев в дереве.

Так как на каждом шаге алгоритма новая полученная область строго включается
в старую, в таком отсортированном списке возможный максимум в поддереве строго
движется вперёд. В итоге за добавление линейного времени на каждый спуск
возможно оценить максимум в поддереве, пересекающийся с текущей рассматриваемой
областью.

\chapter{Тестирование}
\section{Реализация}
За основу была взята реализация алгоритма случайного регрессионного леса из
библиотеки \texttt{sklearn-kit}. 

К стандартному функционалу леса добавлена
функция вычисления максимума или минимума на всем пространстве или же заранее
заданного его подпространстве, с возможностью выбора алгоритма оптимизации, 
допустимой погрешности и количество итераций, если оно используется в текущем 
алгоритме оптимизации.
\section{Параметры тестирования}

Использованные различны общедоступные датасеты с OpenML, их параметры приведены
в таблице~\ref{tab1}.

\begin{center}
    \begin{table}[!h]
    \caption{Таблица с параметрами использованных датасетов}\label{tab1}
        \input{./include/data_table.tex}
    \end{table}
\end{center}

На каждом наборе параметров (то есть: датасет, количество деревьев, максимальная
глубина) обучалось 10 лесов, после чего на каждом запускались алгоритмы
оптимизации. По результатам запусков вычислялось математическое ожидание
и среднеквадратическое отклонение времени работы алгоритма.
Так же вычислялась относительная погрешность результата по следующей формуле:

\[
    \sigma Time = \frac{Max_{correct} - Max_{found} + Min_{correct} - Min_{found}}
    {Max_{correct} - Min_{correct}}
\]

В работе были сравнены следующие алгоритмы: 

\begin{enumerate}
        \item Перебор
        \item Перебор с погрешностью $<5\%$
        \item Случайный
        \item Отжиг
        \item Эвристика
        \item Эвристика с погрешностью $<5\%$
        \item Эвристика с погрешностью $<15\%$
\end{enumerate}

\section{Результаты}
\subsection{Время работы}
    На графиках (Рисунок~\ref{time}) изображено сражение рассматриваемых алгоритмов
    Как видно из графиков время работы эвристического алгоритма 
    оказывается меньше других алгоритмов, особенно при допуске большой погрешности.

\subsection{Точность}
    Как видно из графиков (Рисунок~\ref{error}), даже при большой погрешности эвристический алгоритм
    оказывается более точным нежели другие алгоритмы в сравнении.

    \begin{center}
    \begin{figure}[h!]
    \caption{Сравнение погрешности работы}\label{time}
    \def \graphwidth{0.45\textwidth}
    \def \graphheight{0.35\textheight}
    \begin{tabular}{c c}
        \input{./include/time_easy.tex} &
        \input{./include/time_trees.tex} \\
    \end{tabular}
    \end{figure}
    \begin{figure}[h!]
    \caption{Сравнение времени работы}\label{error}
    \def \graphwidth{0.45\textwidth}
    \def \graphheight{0.35\textheight}
    \begin{tabular}{c c}
        \input{./include/error_easy.tex} &
        \input{./include/error_big.tex} \\
    \end{tabular}
    \end{figure}
    \end{center}

\chapterconclusion{}
    Эвристика демонстрирует лучшее время работы и при даже большой заданной погрешности 
    находит результат более точный чем остальные алгоритмы.

\chapter{Практическое применение}
\section{SMBO и SMAC}
    Последовательная оптимизация основанная на модели (SMBO) Sequential Model-based Algorithm configuration\cite{smbo} (SMAC)
    \begin{enumerate}
    \item Использует случайный лес в качестве регрессионной модели\cite{usesmbo}
    \item В лес добавляются текущие результаты алгоритмов
    \item По значениям леса выбираются новые конфигурации алгоритма
    \end{enumerate}
\section{Модификация с применением разработанного алгоритма}
    Были модифицированы \texttt{automl} реализации с открытым исходным кодом: 
    \texttt{random\_forest\_run} и \texttt{SMAC}. В \texttt{random\_forest\_run} был добавлен
    эвристический алгоритм для поиска минимальной и максимальной области. Последняя оптимизация
    не была реализована, так как она рассчитана на большое количество деревьев. А в \texttt{automl}
    реализации SMAC используется случайный лес с 10 деревьями, и в таком случае данная оптимизация
    лишь замедляет работу алгоритма.

    В модифицированной версии SMAC случайный выбор конфигураций гиперпараметров, заменён на
    возвращение $\alpha * size$ конфигураций из найденной максимальной области случайного леса,
    и оставшиеся $(1 - \alpha) * size$ выбираются случайно. Это делается потому, что текущий 
    регрессионной лес может не точно отражать, реальное поведение целевого алгоритма.
\section{Тестирование и сравнение}
    Для тестирования подбирались гиперпараметры для дерева принятия решений. Этот алгоритм был
    выбран исходя из следующих соображений:
    \begin{itemize}
    \item Быстрый и лёгкий алгоритм, не требующий сложных и длительный вычислений. 
        Так как целевой алгоритм запускается порядка 1000 раз за один тест.
    \item Алгоритм требует подбора гиперпараметров, и без этого работает крайне не эффективно.
        (оценка точности 0.2 с стандартной конфигурацией)
    \end{itemize}

    На графике (Рисунок~\ref{smac_size}) изображена зависимость оценки точности целевого алгоритма
    от размера пространства гиперпараметров. То есть от количества различных комбинаций 
    гиперпараметров. Для этого изначальный набор гиперпараметров был искусственно ограничен, на
    соответствующий коэффициент по всем параметрам.

    На графике (Рисунок~\ref{smac_count}) изображена зависимость оценки точности целевого алгоритма
    от ограничения на количество запусков целевого алгоритма.
    \begin{center}
    \begin{figure}[h!]
    \caption{Зависимость от размера пространства гиперпараметров}\label{smac_size}
    \def \graphwidth{0.8\textwidth}
    \def \graphheight{0.4\textheight}
    \input{./include/smac_size.tex}
    \end{figure}
    \begin{figure}[h!]
    \caption{Зависимость от размера пространства гиперпараметров}\label{smac_count}
    \def \graphwidth{0.8\textwidth}
    \def \graphheight{0.4\textheight}
    \input{./include/smac_count.tex}
    \end{figure}
    \end{center}

\chapterconclusion{}
    Разработанный алгоритм находит своё применение в работе алгоритма подбора гиперпараметров SMAC,
    показывая хорошие результаты и большую устойчивость к размеру пространства гиперпараметров.


%% Макрос для заключения. Совместим со старым стилевиком.
\startconclusionpage{}
    \begin{itemize}
        \item Разработан алгоритм оптимизации случайного леса
        \item Проведено его сравнение с существующими методами
        \item Проверено его практическое применение в сочетании с другими алгоритмами
    \end{itemize}

\printmainbibliography%

\end{document}
