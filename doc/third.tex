\chapter{Тестирование}

\section{Реализация алгоритма}

За основу была взята реализация алгоритма случайного регрессионного леса
\texttt{RandomForestRegressor} из \texttt{Python} библиотеки
\texttt{sklearn-kit}. 

К стандартному функционалу леса добавлена функция вычисления максимума или
минимума на всем пространстве или же заранее заданном его подпространстве,
с возможностью выбора алгоритма оптимизации (случайный поиск, метод ветвей
и границ, метод ветвей и границ с применением эвристик), допустимой погрешности
(для алгоритмов на основе ветвей и границ) и количества итераций (для алгоритмов
на основе случайного или локального поиска). 

\section{Параметры и метод тестирования}

Для обучения случайных лесов применялись общедоступные датасеты из общедоступен
базы данных OpenML, их параметры приведены в таблице~\ref{tab_datasets}.

\begin{center}
    \begin{table}[!ht]
    \caption{Таблица с параметрами использованных датасетов}\label{tab_datasets}
        \input{./include/data_table.tex}
    \end{table}
\end{center}

В работе было произведено сравнение следующих алгоритмов следующие алгоритмы: 

\begin{enumerate}
        \item Перебор
        \item Перебор с погрешностью $<5\%$
        \item Случайный
        \item Отжиг
        \item Эвристика
        \item Эвристика с погрешностью $<5\%$
        \item Эвристика с погрешностью $<15\%$
\end{enumerate}

На каждом наборе параметров (то есть: датасет, количество деревьев, максимальная
глубина) обучалось 10 лесов с разными случайными начальными значениями, после
чего на каждом запускались все рассматриваемые алгоритмы оптимизации. По
результатам запусков вычислялось математическое ожидание и среднеквадратическое
отклонение времени работы алгоритма. Так же вычислялась относительная
погрешность результата по следующей формуле:

\[
    \sigma = \frac{Max_{correct} - Max_{found} + Min_{correct} - Min_{found}}
    {Max_{correct} - Min_{correct}}
\]

\section{Результаты}

\begin{center}

\begin{figure}[!ht]
    \caption{Сравнение времени работы}\label{time}
    \begin{tabular}{c c}
        \timeeasy{0.45\textwidth}{0.35\textheight} &
        \timetrees{0.45\textwidth}{0.35\textheight} \\
    \end{tabular}
\end{figure}

\begin{figure}[!ht]
    \caption{Сравнение погрешности работы}\label{error}
    \begin{tabular}{c c}
        \erroreasy{0.45\textwidth}{0.35\textheight} &
        \errorbig{0.45\textwidth}{0.35\textheight}\\
    \end{tabular}
\end{figure}

\begin{figure}[!ht]
    \caption{Сравнение времени работы в зависимости от погрешности}\label{error_to_time}
    \errortotime{1.0\textwidth}{0.6\textheight}
\end{figure}

\end{center}

\subsection{Время работы}

На графиках (Рисунок~\ref{time}) изображено сражение рассматриваемых
алгоритмов Как видно из графиков время работы эвристического алгоритма
оказывается меньше других алгоритмов, особенно при допуске большой
погрешности.

\subsection{Точность}

Как видно из графиков (Рисунок~\ref{error}), даже при большой погрешности эвристический алгоритм
оказывается более точным нежели другие алгоритмы в сравнении.

\chapterconclusion{}

Эвристика демонстрирует лучшее время работы и при даже большой заданной
погрешности находит результат более точный чем остальные алгоритмы.

\chapter{Практическое применение}

\section{SMBO и SMAC}

Последовательная оптимизация основанная на модели (SMBO) Sequential Model-based
Algorithm configuration\cite{smbo} (SMAC)

\begin{enumerate}
\item Использует случайный лес в качестве регрессионной модели\cite{usesmbo}
\item В лес добавляются текущие результаты алгоритмов
\item По значениям леса выбираются новые конфигурации алгоритма
\end{enumerate}

\section{Модификация с применением разработанного алгоритма}
    
Были модифицированы \texttt{automl} реализации с открытым исходным кодом:
\texttt{random\_forest\_run} и \texttt{SMAC}. В \texttt{random\_forest\_run} был
добавлен эвристический алгоритм для поиска минимальной и максимальной области.
Последняя оптимизация не была реализована, так как она рассчитана на большое
количество деревьев. А в \texttt{automl} реализации SMAC используется случайный
лес с 10 деревьями, и в таком случае данная оптимизация лишь замедляет работу
алгоритма.

В модифицированной версии SMAC случайный выбор конфигураций гиперпараметров,
возвращение $\alpha * size$ конфигураций из найденной максимальной области
случайного леса, и оставшиеся $(1 - \alpha) * size$ выбираются случайно. Это
делается потому, что текущий регрессионной лес может не точно отражать, реальное
поведение целевого алгоритма.

\section{Тестирование и сравнение}

Для тестирования подбирались гиперпараметры для дерева принятия решений. Этот
выбран исходя из следующих соображений:

\begin{itemize}
    \item Быстрый и лёгкий алгоритм, не требующий сложных и длительный вычислений.
    Так как целевой алгоритм запускается порядка 1000 раз за один тест.
    \item Алгоритм требует подбора гиперпараметров, и без этого работает крайне не
    эффективно. (оценка точности 0.2 с стандартной конфигурацией)
\end{itemize}

На графике (Рисунок~\ref{smac_size}) изображена зависимость оценки точности
целевого алгоритма от размера пространства гиперпараметров. То есть от
количества различных комбинаций гиперпараметров. Для этого изначальный набор
гиперпараметров был искусственно ограничен, на соответствующий коэффициент по
всем параметрам.

На графике (Рисунок~\ref{smac_count}) изображена зависимость оценки точности
целевого алгоритма от ограничения на количество запусков целевого алгоритма.

\begin{center}
\begin{figure}[!ht]
\caption{Зависимость от размера пространства гиперпараметров}\label{smac_size}
\smacsize{0.8\textwidth}{0.4\textheight}
\end{figure}
\begin{figure}[!ht]
\caption{Зависимость от размера пространства гиперпараметров}\label{smac_count}
\smaccount{0.8\textwidth}{0.4\textheight}
\end{figure}
\end{center}

\chapterconclusion{}

Разработанный алгоритм находит своё применение в работе алгоритма подбора
гиперпараметров SMAC, показывая хорошие результаты и большую устойчивость
к размеру пространства гиперпараметров.
