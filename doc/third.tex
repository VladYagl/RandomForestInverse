\chapter{Экспериментальное исследование предложенных подходов}\label{chap:third}

\section{Реализация алгоритма}\label{sec:impl}

За основу была взята реализация алгоритма случайного регрессионного леса
\texttt{RandomForestRegressor} из \texttt{Python} библиотеки
\texttt{sklearn-kit}\footnote{\url{http://scikit-learn.org/}}. 

К стандартному функционалу леса добавлена функция вычисления максимума или
минимума на всем пространстве или же заранее заданном его подпространстве,
с возможностью выбора алгоритма оптимизации (случайный поиск, метод ветвей
и границ, метод ветвей и границ с применением эвристик), допустимой погрешности
(для алгоритмов на основе ветвей и границ) и количества итераций (для алгоритмов
на основе случайного или локального поиска). 

\section{Параметры и метод тестирования}\label{sec:test}

Для обучения случайных лесов применялись общедоступные наборы данных из открытой
базы данных OpenML, их параметры приведены в таблице~\ref{tab_datasets}.

\begin{center}
    \begin{table}[H]
    \caption{Таблица с параметрами использованных наборов данных}\label{tab_datasets}
        \input{./include/data_table.tex}
    \end{table}
\end{center}

В работе было произведено сравнение следующих алгоритмов следующие алгоритмы: 

\begin{enumerate}
        \item Метод ветвей и границ 
        \item Метод ветвей и границ с погрешностью $<5\%$
        \item Случайный
        \item Отжиг
        \item Метод ветвей и границ с применением эвристики
        \item Метод ветвей и границ с применением эвристики и с погрешностью $<5\%$
        \item Метод ветвей и границ с применением эвристики и с погрешностью $<15\%$
\end{enumerate}

На каждом наборе параметров (то есть: набор данных, количество деревьев,
максимальная глубина) обучалось 10 лесов с разными случайными начальными
значениями, после чего на каждом запускались все рассматриваемые алгоритмы
оптимизации. По результатам запусков вычислялось математическое ожидание
и среднеквадратическое отклонение времени работы алгоритма. Так же вычислялась
относительная погрешность результата по следующей формуле:

\[
    \sigma = \frac{Max_{correct} - Max_{found} + Min_{correct} - Min_{found}}
    {Max_{correct} - Min_{correct}}
\]

\section{Результаты}\label{sec:results}

\subsection{Время работы}

На графиках (\cref{timeeasy,timetrees,timebig}) изображено сравнение
рассматриваемых алгоритмов по времени их работы в разных условиях. Графики
сгруппированы по характеру начальной выборки, на которой обучался целевой лес,
а так же по количеству деревьев в обучаемом лесу, так как это два основных
параметра влияющих на качество и время работы оптимизации. Пустой столбец на
графике с только одной линией погрешности означает, что алгоритм работал не
целесообразно долго и был остановлен по достижении ограничения на время ($600$
сек.).

\begin{figure}[H]
    \caption{Сравнение времени работы на простых выборках с небольшим
    количеством деревьев ($<50$)}\label{timeeasy}
    \timeeasy{0.90\textwidth}{0.35\textheight}
\end{figure}

Как видно из графика \cref{timeeasy} применение эвристической оптимизации
существенно сокращает время работы алгоритма, в случае не большого количества
неглубоких деревьев. Это происходит, потому что в таком случае первый несколько
найденных ответов приводят к отсечению большого количества поддеревьев, которые
алгоритм не будет рассматривать.

\begin{figure}[H]
    \caption{Сравнение времени работы на простых выборках с большим количеством
    деревьев ($>50$)}\label{timetrees}
    \timetrees{0.75\textwidth}{0.45\textheight} 
\end{figure}

На графике \cref{timetrees} видно, что увеличение количества деревьев, сильно
сказывается на времени работы алгоритмов. Случайный алгоритм очевидно
асимптотически имеет линейную зависимость времени работы, от количества
деревьев, так как он производит константное количество вызовов случайного леса.
В то время как метод ветвей и границ, так как является полным перебор,
потенциально имеет экспоненциальную зависимость. Но на графике видно, что
добавление погрешности в таком случае сильно уменьшает время работы. Это
происходит, потому при большом количестве деревьев, существует множество наборов
поддеревьев имеющих близкие к друг-другу значения потенциальных максимума
и минимума. Особенно хорошо это заметно на наборе данных diabites
(см.~\cref{tab_datasets}) с $50$ деревьями

\begin{figure}[H]
    \caption{Сравнение времени работы на сложных начальных выборках}\label{timebig}
    \timebig{0.80\textwidth}{0.40\textheight} 
\end{figure}

График \cref{timebig} демонстрирует, что сложность изначальной выборки,
а следовательно глубина обученных деревьев, влияет только на время работы
алгоритмов перебора, так как случайный алгоритм не зависит от внутренней
структуры конкретных деревьев леса. При этом в таком случае применение
оптимизации с погрешностью, хоть и даёт выигрыш по времени, но не такой
заметный, как в случае с большим количеством деревьев, так как здесь сложность
работы вызывается перебором поддеревьев одного глубоко дерева, а не поддеревьев
разных деревьев леса.

\subsection{Погрешность}\label{sec:error}

На графиках (\cref{erroreasy,errorbig}) изображено сравнение рассматриваемых
алгоритмов по погрешности найденного значения в разных условиях. Графики
сгруппированы по характеру начальной выборки, на которой обучался целевой лес.
На графиках отсутствуют алгоритмы возвращающие точное значение результата (метод
ветвей и границ без погрешности), так как их погрешность равна $0$.

\begin{figure}[H]
    \caption{Сравнение погрешности работы}\label{erroreasy}
    \erroreasy{0.9\textwidth}{0.45\textheight}
\end{figure}

Как видно из графика \cref{erroreasy} алгоритмы полного перебора стабильно
находят значение точнее заявленной погрешности. Это происходит потому, что
заданное значение погрешности применяется для отсеивания поддеревьев, которые
гарантированно не улучшают найденное значение экстремума. Но так как мы
используем крайнюю оценку возможных значений в поддереве, то на практике это
значение редко достигается и реальное улучшение достижимое в пропущенном
поддереве оказывается сильно меньше оценочного значения. Так же на графике видно
не эффективность реализованного метода отжига. В следствии того, что он
затрачивает большее время на одну итерацию, то при равном ограничении по времени
отжиг оказывается менее эффективным по сравнению с случайным поиском.
В результате, было принято решение отказаться от рассмотрения алгоритма имитации
отжига далее в работе.

\begin{figure}[H]
    \caption{Сравнение погрешности работы на выборках с большим количеством
    признаков.}\label{errorbig}
    \errorbig{0.8\textwidth}{0.45\textheight}
\end{figure} 

График \cref{errorbig} показывает абсолютную не применимость алгоритмов
случайного и локального поиска в случаях большого количества признаков (более
$20$ признаков) в изначальной выборке. В то время, как из-за простой внутренней
структуры алгоритм перебора находит точное значение, даже при большой заданной
погрешности. Особенно хорошо это демонстрирует выборка с более $1000$ признаками
(mtp2 см.~\cref{tab_datasets})

\begin{figure}[H]
    \caption{Сравнение времени работы в зависимости от
    погрешности}\label{error_to_time}
    \errortotime{0.9\textwidth}{0.6\textheight} 
\end{figure}

Чтобы лучше продемонстрировать эффективность описанной раннее оптимизации поиска
с погрешностью. Было произведено сравнение зависимости времени работы алгоритма,
от заданной погрешности в применении на случайные леса обученные на 4 разных
выборках:

\begin{enumerate}
    \item diabetes, с 50 обучаемыми деревьями
    \item kin8nm, с 30 обучаемыми деревьями
    \item house8L, с 37 обучаемыми деревьями
    \item house16L, с 20 обучаемыми деревьями
\end{enumerate}

График \cref{error_to_time} демонстрирует обратную экспоненциальную зависимость
времени работы, от заявленной погрешности применяемого алгоритма. Что
подтверждает сделанное ранее предположение.

\section{Экспериментальное исследование предложенных методов в применении на
практике}\label{sec:test_smac}

Было проведено сравнения модифицированной версии алгоритма SMAC с подбором новых
кандидатов, применяя разработанный алгоритма поиска минимума с случайном лесе.
Тестирование производилось на подборе гиперпараметров для трёх алгоритмов
квалификации из библиотеки sklearn-kit:

\begin{enumerate}
    \item Random Forest Classifier
    \item Decision Tree Classifier
    \item SGD Classifier
\end{enumerate}

Для каждого алгоритма был произведён подбор гиперпараметров применением сначала
оригинального алгоритма SMAC, а затем модифицированной версией алгоритма
с использованием оптимизации случайного леса. На каждой начальной выборке
производилось $10$ запусков SMAC с разными случайными ключами, после чего
вычислялось среднее и погрешность по всем запускам. Для оценки точности
предложенных гиперпараметров, применялась перекрёстная проверка с разбиением
исходной выборки на $5$ равных частей.

Сравнение производилось с двумя алгоритмами использованными в automl реализации
SMAC:\@ случайный поиск и случайный поиск в сочетании локальным поиском. Важно
отметить, что второй алгоритм, хоть и обычно достигает более высоких оценок
точности чем случайный поиск, но это достигается ценой длительного времени
работы. Время работы предложенного алгоритма с применением оптимизации
случайного леса (и случайного поиска) не существенно по сравнению со временем
обучения целевой модели. Так как, в данной реализации применяется не большой
регрессионный лес (10 деревьев), обученный на не большой выборке (количество
запусков целевого алгоритма). Как было продемонстрировано выше в работе, в таком
случае алгоритм крайне эффективен.

\begin{table}[H]
\centering
\caption{Сравнение работы оригинального алгоритма SMAC и с применением оптимизации
случайного леса, выделены те значения где предложенная модификация достигает
лучшей оценки точности.}\label{smacgeneral}
\smacgeneral
\end{table}

В \cref{smacgeneral} продемонстрированы результаты описанного выше
экспериментального исследования. Видно, что в некоторых случаях оба варианта
алгоритма достигают одинаковой оценки точности целевого алгоритма, но можно
заметить, что в таких случаях алгоритм имеет крайне низкий разброс результатов,
а значит, оба алгоритма с большой вероятностью находят лучшую возможную
конфигурацию для данного случая. В случаях с большой погрешностью, предложенная
модификация стабильно достигает лучших оценок точности по сравнению
с оригинальным алгоритмом.

Для тестирования подбирались гиперпараметры для дерева принятия решений. Этот
выбран исходя из следующих соображений:

\begin{itemize}
    \item Быстрый и лёгкий алгоритм, не требующий сложных и длительный вычислений.
    Этот критерий важен, так как целевой алгоритм запускается порядка $1000$ раз за один тест.
    \item Алгоритм требует подбора гиперпараметров, и без этого работает крайне
    не эффективно. (оценка точности $0.2$ со стандартной конфигурацией)
\end{itemize}

\begin{figure}[H]
\caption{Зависимость от размера пространства гиперпараметров}\label{smac_size}
\smacsize{0.6\textwidth}{0.4\textheight}
\end{figure}

На графике~\cref{smac_size} изображена зависимость оценки точности целевого
алгоритма от размера пространства гиперпараметров. То есть от количества
различных комбинаций гиперпараметров. Для этого изначальный набор
гиперпараметров был искусственно ограничен, на соответствующий коэффициент по
всем параметрам. Для каждой выборки было произведено всего по $4$ эксперимента по
причине длительной работы алгоритма SMAC, особенно в его оригинальной
реализации. Изображено по две линии одного цвета для каждого набора данных.
Верхняя линия соответствует предложенной модификации, а нижняя оригинальному
алгоритму. Данный график показывает, что применение предложенного метода
позволяет получать более стабильные результаты при увеличении пространства
гиперпараметров.

\begin{figure}[H]
\caption{Зависимость от размера пространства гиперпараметров}\label{smac_count}
\smaccount{0.6\textwidth}{0.4\textheight}
\end{figure}

На графике~\cref{smac_count} изображена зависимость оценки точности целевого
алгоритма от ограничения на количество запусков целевого алгоритма. Линии на
графике группированы по тому же принципу, что и в предыдущем. График
демонстрирует, что основное преимущество предложенного в работе подхода --- это
сокращение необходимого количества запусков целевого алгоритма, для достижения
той же оценки точности предсказываемого результата. С учётом того, что при этом
алгоритм оптимизации работает значительно меньшее время, предложенный метод
затрачивает значительно меньшее время для достижения эквивалентных результатов.

\chapterconclusion{}

Сначала было произведён вспомогательный сравнительный анализ работы описанных
раннее в работе методов и подходов к оптимизации функции заданной случайным
регрессионным лесом, в ходе которого хорошо заметно превосходящая эффективность
метода ветвей и границ, как в плане времени работы, так и достигаемой при этом
погрешности результата.

Показано и объяснено влияние количества деревьев и глубины деревьев
в оптимизируемой лесу на время и погрешность работы исследуемых алгоритмов.
Произведён анализ зависимости времени работы методов полного перебора от
заданной допустимой погрешности.

После этого метод ветвей и границ был применён в реализации алгоритма SMAC для
оптимизации его регрессионной модели (случайного леса). Разработанный алгоритм
демонстрирует более высокие оценки точности целевой модели при одинаковом наборе
параметров и равном временном бюджете. При этом, чем меньше ограничение по
времени работы и количеству запусков, тем больше заметна разница между
рассматриваемыми алгоритмами.
