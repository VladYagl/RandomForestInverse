@article{bro,
  title={Применение обучения с подкреплением для одновременного выбора модели алгоритма классификации и ее структурных параметров},
  author={Ефимова, Валерия Александровна and Фильченков, Андрей Александрович and Шалыто, Анатолий Абрамович},
  journal={Машинное обучение и анализ данных},
  volume={2},
  number={2},
  pages={244--254},
  year={2016},
  publisher={Федеральное государственное бюджетное учреждение науки Вычислительный центр~…}
}

@techreport{smac,
  title={Sequential model-based optimization for general algorithm configuration (extended version)},
  author={Hutter, Frank and Hoos, Holger H and Leyton-Brown, Kevin},
  year={2010},
  institution={Technical Report TR-2010-10, University of British Columbia, Computer Science},
   langid = {english}
}

@inproceedings{usesmbo,
  title={Initializing bayesian hyperparameter optimization via meta-learning},
  author={Feurer, Matthias and Springenberg, Jost Tobias and Hutter, Frank},
  booktitle={Twenty-Ninth AAAI Conference on Artificial Intelligence},
  year={2015},
   langid = {english} 
}

@article{randomforest,
  title={Classification and regression by randomForest},
  author={Liaw, Andy and Wiener, Matthew and others},
  journal={R news},
  volume={2},
  number={3},
  pages={18--22},
  year={2002},
   langid = {english}
}

@book{globalopt,
  title={Towards global optimisation 2},
  author={Dixon, Laurence Charles Ward and Szeg{\"o}, Giorgio Philip},
  year={1978},
  publisher={North-Holland Amsterdam},
   langid = {english}
}

@article{gaussbandit,
  title={Gaussian process optimization in the bandit setting: No regret and experimental design},
  author={Srinivas, Niranjan and Krause, Andreas and Kakade, Sham M and Seeger, Matthias},
  journal={arXiv preprint arXiv:0912.3995},
  year={2009},
   langid = {english}
}

@MISC{tree,
    author = {J. R. Quinlan},
    title = {Simplifying Decision Trees},
    year = {1986},
     langid = {english}
}

@inproceedings{pruning,
  title={MDL-Based Decision Tree Pruning.},
  author={Mehta, Manish and Rissanen, Jorma and Agrawal, Rakesh and others},
  booktitle={KDD},
  volume={21},
  number={2},
  pages={216--221},
  year={1995},
   langid = {english}
}

@article{bagging,
  title={An introduction to recursive partitioning: rationale, application, and characteristics of classification and regression trees, bagging, and random forests.},
  author={Strobl, Carolin and Malley, James and Tutz, Gerhard},
  journal={Psychological methods},
  volume={14},
  number={4},
  pages={323},
  year={2009},
  publisher={American Psychological Association},
   langid = {english}
}

@book{optimize,
  title={Комбинаторные методы и алгоритмы решения задач дискретной оптимизации большой размерности},
  author={Хачатуров, ВР and Веселовский, ВЕ and Злотов, АВ and Калдыбаев, СУ and Калиев, ЕЖ and Коваленко, АГ and Монтлевич, ВМ and Сигал, ИХ and Хачатуров, РВ},
  year={2000},
  publisher={Наука М.}
}

@article{random,
  title={Random search for hyper-parameter optimization},
  author={Bergstra, James and Bengio, Yoshua},
  journal={Journal of Machine Learning Research},
  volume={13},
  number={Feb},
  pages={281--305},
  year={2012},
   langid = {english}
}

@inproceedings{local,
  title={Combining search-based and constraint-based testing},
  author={Malburg, Jan and Fraser, Gordon},
  booktitle={Proceedings of the 2011 26th IEEE/ACM International Conference on Automated Software Engineering},
  pages={436--439},
  year={2011},
  organization={IEEE Computer Society},
   langid = {english}
}

@article{od,
  title={Метод имитации отжига},
  author={Глушань, ВМ},
  journal={Известия Южного федерального университета. Технические науки},
  volume={31},
  number={2},
  year={2003},
  publisher={Федеральное государственное автономное образовательное учреждение высшего~…}
}

@article{branch,
 ISSN = {00129682, 14680262},
 URL = {http://www.jstor.org/stable/1910129},
 abstract = {In the classical linear programming problem the behaviour of continuous, nonnegative variables subject to a system of linear inequalities is investigated. One possible generalization of this problem is to relax the continuity condition the variables. This paper presents a simple numerical algorithm for the solution of programming problems in which some or all of the variables can take only discrete values. The algorithm requires no special techniques beyond these used in ordinary linear programming, and lends itself to automatic computing. Its use is illustrated on two numerical examples.},
 author = {A. H. Land and A. G. Doig},
 journal = {Econometrica},
 number = {3},
 pages = {497--520},
 publisher = {[Wiley, Econometric Society]},
 title = {An Automatic Method of Solving Discrete Programming Problems},
 volume = {28},
 year = {1960},
  langid = {english}
}

@article{elf,
  title={Reinforcement-based Method for Simultaneous Clustering Algorithm Selection and its Hyperparameters Optimization},
  author={Shalamov, Viacheslav and Efimova, Valeria and Muravyov, Sergey and Filchenkov, Andrey},
  journal={Procedia Computer Science},
  volume={136},
  pages={144--153},
  year={2018},
  publisher={Elsevier}
}

@inproceedings{bayes1,
  title={Initializing bayesian hyperparameter optimization via meta-learning},
  author={Feurer, Matthias and Springenberg, Jost Tobias and Hutter, Frank},
  booktitle={Twenty-Ninth AAAI Conference on Artificial Intelligence},
  year={2015},
  langid = {english}
}
